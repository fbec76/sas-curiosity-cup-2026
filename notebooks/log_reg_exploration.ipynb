{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-15T19:13:24.265051Z",
     "start_time": "2026-02-15T19:13:23.533973Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import requests\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:13:24.285215Z",
     "start_time": "2026-02-15T19:13:24.265888Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_STATE = 42",
   "id": "66afc18375a2f987",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:13:26.321619Z",
     "start_time": "2026-02-15T19:13:24.286210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set to True to download data from GitHub, False to load from local processed directory\n",
    "DOWNLOAD = False\n",
    "\n",
    "if DOWNLOAD:\n",
    "    # Download CSV files from GitHub repository\n",
    "    directory = \"./downloads/\"\n",
    "    filenames = [\n",
    "        \"master_data.parquet\",\n",
    "        \"master_data_dropped.parquet\",\n",
    "        \"master_data_imputed.parquet\"\n",
    "    ]\n",
    "\n",
    "    # Common URL parts\n",
    "    base_url = \"https://github.com/fbec76/sas-curiosity-cup-2026/raw/refs/heads/main/datasets/processed/\"\n",
    "    for fname in filenames:\n",
    "        url = base_url + fname + \"?download=\"\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            with open(directory + fname, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded: {fname}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {fname}\")\n",
    "    data_dir = \"./downloads/\"\n",
    "    master_data_orig = pd.read_parquet(data_dir + \"master_data.parquet\")\n",
    "    master_data_dropped_orig = pd.read_parquet(data_dir + \"master_data_dropped.parquet\")\n",
    "    master_data_imputed_orig = pd.read_parquet(data_dir + \"master_data_imputed.parquet\")\n",
    "    print(\"Data loaded from downloads directory.\")\n",
    "else:\n",
    "    master_data_orig = pd.read_parquet(\"../datasets/processed/master_data.parquet\")\n",
    "    master_data_dropped_orig = pd.read_parquet(\"../datasets/processed/master_data_dropped.parquet\")\n",
    "    master_data_imputed_orig = pd.read_parquet(\"../datasets/processed/master_data_imputed.parquet\")\n",
    "    data_dir = \"../datasets/processed/\"\n",
    "    print(\"Data loaded from processed directory.\")\n"
   ],
   "id": "db56959cb301fa64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from processed directory.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:13:58.590633Z",
     "start_time": "2026-02-15T19:13:49.531255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "master_data = master_data_orig.copy()\n",
    "master_data_dropped = master_data_dropped_orig.copy()\n",
    "master_data_imputed = master_data_imputed_orig.copy()"
   ],
   "id": "95f2263743c5b571",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:14:04.322695Z",
     "start_time": "2026-02-15T19:14:04.285120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _fit_linear_classifier(\n",
    "        df,\n",
    "        target,\n",
    "        features_list,\n",
    "        continuous_features,\n",
    "        cv_folds=5,\n",
    "        scoring=\"f1\",\n",
    "        model_type=\"logreg\",  # \"logreg\" or \"sgd\"\n",
    "        penalty_type=\"lasso\",  # \"lasso\" or \"ridge\"\n",
    "        sgd_max_iter=2000,\n",
    "        sgd_tol=1e-3,\n",
    "):\n",
    "    import pandas as pd\n",
    "\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X = df[features_list]\n",
    "    y = df[target]\n",
    "\n",
    "    start_time = pd.Timestamp.now()\n",
    "\n",
    "    # Only scale columns that are actually used and exist\n",
    "    continuous_present = [c for c in continuous_features if c in features_list]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), continuous_present),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    if model_type == \"logreg\":\n",
    "        # LogisticRegression with elasticnet via saga\n",
    "        l1_ratio = 1.0 if penalty_type == \"lasso\" else 0.0\n",
    "        clf = LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            solver=\"saga\",\n",
    "            l1_ratio=l1_ratio,\n",
    "            max_iter=10000,\n",
    "        )\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"clf\", clf),\n",
    "            ]\n",
    "        )\n",
    "        param_grid = {\"clf__C\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "    elif model_type == \"sgd\":\n",
    "        # SGDClassifier approximates logistic regression when loss='log_loss'\n",
    "        penalty = \"l1\" if penalty_type == \"lasso\" else \"l2\"\n",
    "        clf = SGDClassifier(\n",
    "            loss=\"log_loss\",\n",
    "            penalty=penalty,\n",
    "            max_iter=sgd_max_iter,\n",
    "            tol=sgd_tol,\n",
    "            random_state=42,\n",
    "        )\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"clf\", clf),\n",
    "            ]\n",
    "        )\n",
    "        param_grid = {\"clf__alpha\": [1e-2, 1e-3, 1e-4, 1e-5]}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'logreg' or 'sgd'\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # CV predictions from the selected (tuned) pipeline\n",
    "    y_pred_cv = cross_val_predict(best_model, X, y, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "    print(\"Scaled continuous columns (present):\", continuous_present)\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Classification Report (CV preds):\\n\", classification_report(y, y_pred_cv))\n",
    "    print(\"Confusion Matrix (CV preds):\\n\", confusion_matrix(y, y_pred_cv))\n",
    "    print(\"Time taken:\", pd.Timestamp.now() - start_time)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def lasso_logistic_regression(\n",
    "        df,\n",
    "        target,\n",
    "        features_list,\n",
    "        continuous_features,\n",
    "        cv_folds=5,\n",
    "        model_type=\"logreg\",\n",
    "        scoring=\"f1\",\n",
    "):\n",
    "    return _fit_linear_classifier(\n",
    "        df=df,\n",
    "        target=target,\n",
    "        features_list=features_list,\n",
    "        continuous_features=continuous_features,\n",
    "        cv_folds=cv_folds,\n",
    "        scoring=scoring,\n",
    "        model_type=model_type,\n",
    "        penalty_type=\"lasso\",\n",
    "    )\n",
    "\n",
    "\n",
    "def ridge_logistic_regression(\n",
    "        df,\n",
    "        target,\n",
    "        features_list,\n",
    "        continuous_features,\n",
    "        cv_folds=5,\n",
    "        model_type=\"logreg\",\n",
    "        scoring=\"f1\",\n",
    "):\n",
    "    return _fit_linear_classifier(\n",
    "        df=df,\n",
    "        target=target,\n",
    "        features_list=features_list,\n",
    "        continuous_features=continuous_features,\n",
    "        cv_folds=cv_folds,\n",
    "        scoring=scoring,\n",
    "        model_type=model_type,\n",
    "        penalty_type=\"ridge\",\n",
    "    )"
   ],
   "id": "b1a64d7f96f03b5e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:14:05.974925Z",
     "start_time": "2026-02-15T19:14:04.864551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop GAME_DATE column from master_data_dropped and master_data_imputed\n",
    "master_data_dropped = master_data_dropped.drop(columns=[\"GAME_DATE\"])\n",
    "master_data_imputed = master_data_imputed.drop(columns=[\"GAME_DATE\"])\n",
    "\n",
    "# conver POS_ columns to boolean in master_data_dropped\n",
    "pos_columns = [col for col in master_data_dropped.columns if col.startswith(\"POS_\")]\n",
    "master_data_dropped[pos_columns] = master_data_dropped[pos_columns].astype(bool)"
   ],
   "id": "4061a191981a4370",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:14:12.163805Z",
     "start_time": "2026-02-15T19:14:08.436508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define target variable and features list\n",
    "target_variable = \"MADE_SHOT\"\n",
    "\n",
    "# features list for master_data_dropped\n",
    "cols_to_exclude = [\n",
    "    target_variable, \"GAME_ID\", \"PLAYER_ID\", \"PLAYER_NAME\", \"TEAM_ID\", \"TEAM_NAME\",\n",
    "    \"LAT\", \"LON\", \"D_LAT\", \"D_LON\", \"FLIGHT_TIME_MIN\", \"HOME_TEAM\", \"AWAY_TEAM\", \"IS_3PT\"\n",
    "]\n",
    "\n",
    "features_list = master_data_dropped.columns.difference(cols_to_exclude).tolist()\n",
    "\n",
    "features_list_dropped = features_list\n",
    "features_list_imputed = [col for col in features_list if not col.startswith(\"POS_\")]\n",
    "\n",
    "# Continuous features to normalize (z-score)\n",
    "continuous_features = [\n",
    "    \"BODY_FAT_PCT\",\n",
    "    \"DISTANCE_KM\",\n",
    "    \"HAND_LENGTH_CM\",\n",
    "    \"HAND_WIDTH_CM\",\n",
    "    \"HEIGHT_CM\",\n",
    "    \"LANE_AGILITY_TIME_S\",\n",
    "    \"LOC_X_CM\",\n",
    "    \"LOC_Y_CM\",\n",
    "    \"MAX_VERTICAL_LEAP_CM\",\n",
    "    \"REST_D\",\n",
    "    \"SEASON\",  # normalize to allow learning an overall trend\n",
    "    \"SHOT_DISTANCE_CM\",\n",
    "    \"STANDING_REACH_CM\",\n",
    "    \"STANDING_VERTICAL_LEAP_CM\",\n",
    "    \"THREE_QUARTER_SPRINT_S\",\n",
    "    \"TIME_LEFT_S\",\n",
    "    \"TZ_SHIFT\",\n",
    "    \"WEIGHT_KG\",\n",
    "    \"WINGSPAN_CM\",\n",
    "]\n",
    "\n",
    "# One-hot encode QUARTER\n",
    "if \"QUARTER\" in master_data_dropped.columns:\n",
    "    master_data_dropped = pd.get_dummies(\n",
    "        master_data_dropped,\n",
    "        columns=[\"QUARTER\"],\n",
    "        prefix=\"QUARTER\",\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "if \"QUARTER\" in master_data_imputed.columns:\n",
    "    master_data_imputed = pd.get_dummies(\n",
    "        master_data_imputed,\n",
    "        columns=[\"QUARTER\"],\n",
    "        prefix=\"QUARTER\",\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "# Ensure we only scale columns that exist (robust to missing columns)\n",
    "continuous_features_present = [c for c in continuous_features if c in master_data_dropped.columns]\n",
    "\n",
    "# Rebuild features_list after one-hot encoding QUARTER (new columns added)\n",
    "features_list = master_data_dropped.columns.difference(cols_to_exclude).tolist()\n",
    "\n",
    "features_list_dropped = features_list\n",
    "features_list_imputed = [col for col in features_list if not col.startswith(\"POS_\")]"
   ],
   "id": "42062da0b9e3f6ed",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:14:21.581962Z",
     "start_time": "2026-02-15T19:14:18.553407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# randomize order in master_data_dropped and master_data_imputed\n",
    "master_data_dropped = master_data_dropped.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "master_data_imputed = master_data_imputed.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)"
   ],
   "id": "894ec6698c662bf0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T19:16:36.471931Z",
     "start_time": "2026-02-15T19:16:35.414209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run LASSO logistic regression on 25% sample of master_data_dropped\n",
    "print(\"Running LASSO logistic regression on master_data_dropped (25% sample)...\")\n",
    "\n",
    "lasso_model_dropped = lasso_logistic_regression(\n",
    "    df=master_data_dropped.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_dropped,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    model_type=\"sgd\",\n",
    "    scoring=\"f1\",\n",
    ")"
   ],
   "id": "fa62feb5a1888289",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LASSO logistic regression on master_data_dropped (25% sample)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Run LASSO logistic regression on 25% sample of master_data_dropped\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mRunning LASSO logistic regression on master_data_dropped (25\u001B[39m\u001B[38;5;132;01m% s\u001B[39;00m\u001B[33mample)...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m lasso_model_dropped = \u001B[43mlasso_logistic_regression\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmaster_data_dropped\u001B[49m\u001B[43m.\u001B[49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrac\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mRANDOM_STATE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_variable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfeatures_list_dropped\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcv_folds\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msgd\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mf1\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     11\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 66\u001B[39m, in \u001B[36mlasso_logistic_regression\u001B[39m\u001B[34m(df, target, features_list, cv_folds, model_type, scoring)\u001B[39m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlasso_logistic_regression\u001B[39m(df, target, features_list, cv_folds=\u001B[32m5\u001B[39m, model_type=\u001B[33m\"\u001B[39m\u001B[33mlogreg\u001B[39m\u001B[33m\"\u001B[39m, scoring=\u001B[33m\"\u001B[39m\u001B[33mf1\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_fit_linear_classifier\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfeatures_list\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfeatures_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcv_folds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcv_folds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpenalty_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlasso\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 51\u001B[39m, in \u001B[36m_fit_linear_classifier\u001B[39m\u001B[34m(df, target, features_list, cv_folds, scoring, model_type, penalty_type, sgd_max_iter, sgd_tol)\u001B[39m\n\u001B[32m     42\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mmodel_type must be \u001B[39m\u001B[33m'\u001B[39m\u001B[33mlogreg\u001B[39m\u001B[33m'\u001B[39m\u001B[33m or \u001B[39m\u001B[33m'\u001B[39m\u001B[33msgd\u001B[39m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     44\u001B[39m grid_search = GridSearchCV(\n\u001B[32m     45\u001B[39m     estimator=model,\n\u001B[32m     46\u001B[39m     param_grid=param_grid,\n\u001B[32m   (...)\u001B[39m\u001B[32m     49\u001B[39m     n_jobs=-\u001B[32m1\u001B[39m,\n\u001B[32m     50\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m best_model = grid_search.best_estimator_\n\u001B[32m     55\u001B[39m y_pred_cv = cross_val_predict(best_model, X, y, cv=cv_folds, n_jobs=-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/base.py:1336\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1329\u001B[39m     estimator._validate_params()\n\u001B[32m   1331\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1332\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1333\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1334\u001B[39m     )\n\u001B[32m   1335\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1336\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1053\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1047\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1048\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1049\u001B[39m     )\n\u001B[32m   1051\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1053\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1055\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1056\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1057\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1612\u001B[39m, in \u001B[36mGridSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1610\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1611\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1612\u001B[39m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1011\u001B[39m, in \u001B[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[39m\u001B[34m(candidate_params, cv, more_results)\u001B[39m\n\u001B[32m    991\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose > \u001B[32m0\u001B[39m:\n\u001B[32m    992\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    993\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m candidates,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    994\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m fits\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    995\u001B[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001B[32m    996\u001B[39m         )\n\u001B[32m    997\u001B[39m     )\n\u001B[32m    999\u001B[39m out = parallel(\n\u001B[32m   1000\u001B[39m     delayed(_fit_and_score)(\n\u001B[32m   1001\u001B[39m         clone(base_estimator),\n\u001B[32m   1002\u001B[39m         X,\n\u001B[32m   1003\u001B[39m         y,\n\u001B[32m   1004\u001B[39m         train=train,\n\u001B[32m   1005\u001B[39m         test=test,\n\u001B[32m   1006\u001B[39m         parameters=parameters,\n\u001B[32m   1007\u001B[39m         split_progress=(split_idx, n_splits),\n\u001B[32m   1008\u001B[39m         candidate_progress=(cand_idx, n_candidates),\n\u001B[32m   1009\u001B[39m         **fit_and_score_kwargs,\n\u001B[32m   1010\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1011\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001B[38;5;129;01min\u001B[39;00m \u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1012\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1014\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1015\u001B[39m )\n\u001B[32m   1017\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) < \u001B[32m1\u001B[39m:\n\u001B[32m   1018\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1019\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNo fits were performed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1020\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWas the CV iterator empty? \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1021\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWere there no candidates?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1022\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:412\u001B[39m, in \u001B[36m_BaseKFold.split\u001B[39m\u001B[34m(self, X, y, groups)\u001B[39m\n\u001B[32m    404\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_splits > n_samples:\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    406\u001B[39m         (\n\u001B[32m    407\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mCannot have number of splits n_splits=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m greater\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    408\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m than the number of samples: n_samples=\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    409\u001B[39m         ).format(\u001B[38;5;28mself\u001B[39m.n_splits, n_samples)\n\u001B[32m    410\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m412\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:143\u001B[39m, in \u001B[36mBaseCrossValidator.split\u001B[39m\u001B[34m(self, X, y, groups)\u001B[39m\n\u001B[32m    141\u001B[39m X, y, groups = indexable(X, y, groups)\n\u001B[32m    142\u001B[39m indices = np.arange(_num_samples(X))\n\u001B[32m--> \u001B[39m\u001B[32m143\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtest_index\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_test_masks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    144\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_index\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlogical_not\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_index\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    145\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_index\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_index\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:846\u001B[39m, in \u001B[36mStratifiedKFold._iter_test_masks\u001B[39m\u001B[34m(self, X, y, groups)\u001B[39m\n\u001B[32m    845\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_iter_test_masks\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y=\u001B[38;5;28;01mNone\u001B[39;00m, groups=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m846\u001B[39m     test_folds = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_test_folds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    847\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.n_splits):\n\u001B[32m    848\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m test_folds == i\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/sklearn/model_selection/_split.py:797\u001B[39m, in \u001B[36mStratifiedKFold._make_test_folds\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    790\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mSupported target types are: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m. Got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[33m instead.\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    791\u001B[39m             allowed_target_types, type_of_target_y\n\u001B[32m    792\u001B[39m         )\n\u001B[32m    793\u001B[39m     )\n\u001B[32m    795\u001B[39m y = column_or_1d(y)\n\u001B[32m--> \u001B[39m\u001B[32m797\u001B[39m _, y_idx, y_inv = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_index\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[38;5;66;03m# y_inv encodes y according to lexicographic order. We invert y_idx to\u001B[39;00m\n\u001B[32m    799\u001B[39m \u001B[38;5;66;03m# map the classes so that they are encoded by order of appearance:\u001B[39;00m\n\u001B[32m    800\u001B[39m \u001B[38;5;66;03m# 0 represents the first label appearing in y, 1 the second, etc.\u001B[39;00m\n\u001B[32m    801\u001B[39m _, class_perm = np.unique(y_idx, return_inverse=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/numpy/lib/_arraysetops_impl.py:296\u001B[39m, in \u001B[36munique\u001B[39m\u001B[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan, sorted)\u001B[39m\n\u001B[32m    294\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    295\u001B[39m         normalize_axis_index(axis, ar.ndim)\n\u001B[32m--> \u001B[39m\u001B[32m296\u001B[39m     ret = \u001B[43m_unique1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m                    \u001B[49m\u001B[43mequal_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mequal_nan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minverse_shape\u001B[49m\u001B[43m=\u001B[49m\u001B[43mar\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m                    \u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    299\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _unpack_tuple(ret)\n\u001B[32m    301\u001B[39m \u001B[38;5;66;03m# axis was specified and not None\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/uni/sas-curiosity-cup-2026/.venv/lib/python3.13/site-packages/numpy/lib/_arraysetops_impl.py:408\u001B[39m, in \u001B[36m_unique1d\u001B[39m\u001B[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis, sorted)\u001B[39m\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_inverse:\n\u001B[32m    407\u001B[39m     imask = np.cumsum(mask) - \u001B[32m1\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m408\u001B[39m     inv_idx = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mintp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    409\u001B[39m     inv_idx[perm] = imask\n\u001B[32m    410\u001B[39m     ret += (inv_idx.reshape(inverse_shape) \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m inv_idx,)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the coefficients of the LASSO model and sort them by absolute value\n",
    "lasso_coefficients = pd.Series(lasso_model_dropped.coef_[0], index=features_list_dropped)\n",
    "lasso_coefficients_sorted = lasso_coefficients.reindex(lasso_coefficients.abs().sort_values(ascending=False).index)\n",
    "print(\"LASSO Coefficients sorted by absolute value:\")\n",
    "lasso_coefficients_sorted"
   ],
   "id": "23d292c3a9cd4953",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run Ridge logistic regression on 25% sample of master_data_dropped\n",
    "print(\"Running Ridge logistic regression on master_data_dropped (25% sample)...\")\n",
    "\n",
    "ridge_model_dropped = ridge_logistic_regression(\n",
    "    df=master_data_dropped.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_dropped,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    model_type=\"sgd\",\n",
    "    scoring=\"f1\",\n",
    ")"
   ],
   "id": "887ddc93e1fa837b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the coefficients of the Ridge model and sort them by absolute value\n",
    "ridge_coefficients = pd.Series(ridge_model_dropped.coef_[0], index=features_list_dropped)\n",
    "ridge_coefficients_sorted = ridge_coefficients.reindex(ridge_coefficients.abs().sort_values(ascending=False).index)\n",
    "print(\"Ridge Coefficients sorted by absolute value:\")\n",
    "ridge_coefficients_sorted"
   ],
   "id": "8a4773c324fbde1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run LASSO logistic regression on 25% sample of master_data_imputed\n",
    "print(\"Running LASSO logistic regression on master_data_imputed (25% sample)...\")\n",
    "\n",
    "lasso_model_imputed = lasso_logistic_regression(\n",
    "    df=master_data_imputed.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_imputed,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    model_type=\"sgd\",\n",
    "    scoring=\"f1\",\n",
    ")"
   ],
   "id": "8614f81a8a889b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the coefficients of the LASSO model and sort them by absolute value\n",
    "lasso_coefficients_imputed = pd.Series(lasso_model_imputed.coef_[0], index=features_list_imputed)\n",
    "lasso_coefficients_imputed_sorted = lasso_coefficients_imputed.reindex(\n",
    "    lasso_coefficients_imputed.abs().sort_values(ascending=False).index)\n",
    "print(\"LASSO Coefficients (imputed) sorted by absolute value:\")\n",
    "lasso_coefficients_imputed_sorted"
   ],
   "id": "103c51da49bfe743",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run Ridge logistic regression on 10% sample of master_data_imputed\n",
    "print(\"Running Ridge logistic regression on master_data_imputed (25% sample)...\")\n",
    "\n",
    "ridge_model_imputed = ridge_logistic_regression(\n",
    "    df=master_data_imputed.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_imputed,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    model_type=\"sgd\",\n",
    "    scoring=\"f1\",\n",
    ")"
   ],
   "id": "8b6ec0309f912a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the coefficients of the Ridge model and sort them by absolute value\n",
    "ridge_coefficients_imputed = pd.Series(ridge_model_imputed.coef_[0], index=features_list_imputed)\n",
    "ridge_coefficients_imputed_sorted = ridge_coefficients_imputed.reindex(\n",
    "    ridge_coefficients_imputed.abs().sort_values(ascending=False).index)\n",
    "print(\"Ridge Coefficients (imputed) sorted by absolute value:\")\n",
    "ridge_coefficients_imputed_sorted"
   ],
   "id": "a6da41436d7b1c05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
