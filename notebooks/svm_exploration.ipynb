{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:41.595115Z",
     "start_time": "2026-02-15T22:38:41.572618Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import requests\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:41.845214Z",
     "start_time": "2026-02-15T22:38:41.836264Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_STATE = 42",
   "id": "b54f8eb7543cfe71",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:44.541680Z",
     "start_time": "2026-02-15T22:38:42.150519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set to True to download data from GitHub, False to load from local processed directory\n",
    "DOWNLOAD = False\n",
    "\n",
    "if DOWNLOAD:\n",
    "    # Download CSV files from GitHub repository\n",
    "    directory = \"./downloads/\"\n",
    "    filenames = [\n",
    "        \"master_data.parquet\",\n",
    "        \"master_data_dropped.parquet\",\n",
    "        \"master_data_imputed.parquet\"\n",
    "    ]\n",
    "\n",
    "    # Common URL parts\n",
    "    base_url = \"https://github.com/fbec76/sas-curiosity-cup-2026/raw/refs/heads/main/datasets/processed/\"\n",
    "    for fname in filenames:\n",
    "        url = base_url + fname + \"?download=\"\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            with open(directory + fname, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded: {fname}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {fname}\")\n",
    "    data_dir = \"./downloads/\"\n",
    "    master_data_orig = pd.read_parquet(data_dir + \"master_data.parquet\")\n",
    "    master_data_dropped_orig = pd.read_parquet(data_dir + \"master_data_dropped.parquet\")\n",
    "    master_data_imputed_orig = pd.read_parquet(data_dir + \"master_data_imputed.parquet\")\n",
    "    print(\"Data loaded from downloads directory.\")\n",
    "else:\n",
    "    master_data_orig = pd.read_parquet(\"../datasets/processed/master_data.parquet\")\n",
    "    master_data_dropped_orig = pd.read_parquet(\"../datasets/processed/master_data_dropped.parquet\")\n",
    "    master_data_imputed_orig = pd.read_parquet(\"../datasets/processed/master_data_imputed.parquet\")\n",
    "    data_dir = \"../datasets/processed/\"\n",
    "    print(\"Data loaded from processed directory.\")\n"
   ],
   "id": "89cb2006fff88bfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from processed directory.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:47.198761Z",
     "start_time": "2026-02-15T22:38:44.567805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "master_data = master_data_orig.copy()\n",
    "master_data_dropped = master_data_dropped_orig.copy()\n",
    "master_data_imputed = master_data_imputed_orig.copy()"
   ],
   "id": "8dde1f1155ce433",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:48.423145Z",
     "start_time": "2026-02-15T22:38:47.244730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop GAME_DATE column from master_data_dropped and master_data_imputed\n",
    "master_data_dropped = master_data_dropped.drop(columns=[\"GAME_DATE\"])\n",
    "master_data_imputed = master_data_imputed.drop(columns=[\"GAME_DATE\"])\n",
    "\n",
    "# conver POS_ columns to boolean in master_data_dropped\n",
    "pos_columns = [col for col in master_data_dropped.columns if col.startswith(\"POS_\")]\n",
    "master_data_dropped[pos_columns] = master_data_dropped[pos_columns].astype(bool)"
   ],
   "id": "b7d6bb969e7b0a50",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:38:50.512996Z",
     "start_time": "2026-02-15T22:38:48.443667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define target variable and features list\n",
    "target_variable = \"MADE_SHOT\"\n",
    "\n",
    "# features list for master_data_dropped\n",
    "cols_to_exclude = [\n",
    "    target_variable, \"GAME_ID\", \"PLAYER_ID\", \"PLAYER_NAME\", \"TEAM_ID\", \"TEAM_NAME\",\n",
    "    \"LAT\", \"LON\", \"D_LAT\", \"D_LON\", \"FLIGHT_TIME_MIN\", \"HOME_TEAM\", \"AWAY_TEAM\", \"IS_3PT\"\n",
    "]\n",
    "\n",
    "features_list = master_data_dropped.columns.difference(cols_to_exclude).tolist()\n",
    "\n",
    "features_list_dropped = features_list\n",
    "features_list_imputed = [col for col in features_list if not col.startswith(\"POS_\")]\n",
    "\n",
    "# Continuous features to normalize (z-score)\n",
    "continuous_features = [\n",
    "    \"BODY_FAT_PCT\",\n",
    "    \"DISTANCE_KM\",\n",
    "    \"HAND_LENGTH_CM\",\n",
    "    \"HAND_WIDTH_CM\",\n",
    "    \"HEIGHT_CM\",\n",
    "    \"LANE_AGILITY_TIME_S\",\n",
    "    \"LOC_X_CM\",\n",
    "    \"LOC_Y_CM\",\n",
    "    \"MAX_VERTICAL_LEAP_CM\",\n",
    "    \"REST_D\",\n",
    "    \"SEASON\",  # normalize to allow learning an overall trend\n",
    "    \"SHOT_DISTANCE_CM\",\n",
    "    \"STANDING_REACH_CM\",\n",
    "    \"STANDING_VERTICAL_LEAP_CM\",\n",
    "    \"THREE_QUARTER_SPRINT_S\",\n",
    "    \"TIME_LEFT_S\",\n",
    "    \"TZ_SHIFT\",\n",
    "    \"WEIGHT_KG\",\n",
    "    \"WINGSPAN_CM\",\n",
    "]\n",
    "\n",
    "# One-hot encode QUARTER\n",
    "if \"QUARTER\" in master_data_dropped.columns:\n",
    "    master_data_dropped = pd.get_dummies(\n",
    "        master_data_dropped,\n",
    "        columns=[\"QUARTER\"],\n",
    "        prefix=\"QUARTER\",\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "if \"QUARTER\" in master_data_imputed.columns:\n",
    "    master_data_imputed = pd.get_dummies(\n",
    "        master_data_imputed,\n",
    "        columns=[\"QUARTER\"],\n",
    "        prefix=\"QUARTER\",\n",
    "        drop_first=False\n",
    "    )\n",
    "\n",
    "# Ensure we only scale columns that exist (robust to missing columns)\n",
    "continuous_features_present = [c for c in continuous_features if c in master_data_dropped.columns]\n",
    "\n",
    "# Rebuild features_list after one-hot encoding QUARTER (new columns added)\n",
    "features_list = master_data_dropped.columns.difference(cols_to_exclude).tolist()\n",
    "\n",
    "features_list_dropped = features_list\n",
    "features_list_imputed = [col for col in features_list if not col.startswith(\"POS_\")]"
   ],
   "id": "d47e73b261dcb1e6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:53:45.922493Z",
     "start_time": "2026-02-15T22:53:45.900138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def svm_classifier_with_scaling(\n",
    "        df,\n",
    "        target,\n",
    "        features_list,\n",
    "        continuous_features,\n",
    "        cv_folds=5,\n",
    "        scoring=\"f1\",\n",
    "        kernel=\"rbf\",  # \"rbf\" or \"poly\"\n",
    "):\n",
    "    X = df[features_list]\n",
    "    y = df[target]\n",
    "\n",
    "    start_time = pd.Timestamp.now()\n",
    "\n",
    "    if kernel not in {\"rbf\", \"poly\"}:\n",
    "        raise ValueError(\"kernel must be 'rbf' or 'poly'\")\n",
    "\n",
    "    # Only scale columns that are actually used and exist\n",
    "    continuous_present = [c for c in continuous_features if c in features_list]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), continuous_present),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"svc\", SVC(kernel=kernel)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if kernel == \"rbf\":\n",
    "        param_grid = {\n",
    "            \"svc__C\": [0.1, 1, 10, 100],\n",
    "            # \"svc__gamma\": [\"scale\", \"auto\", 1e-3, 1e-2, 1e-1],\n",
    "        }\n",
    "    else:  # poly\n",
    "        param_grid = {\n",
    "            \"svc__C\": [0.1, 1, 10, 100],\n",
    "            # \"svc__gamma\": [\"scale\", \"auto\", 1e-3, 1e-2, 1e-1],\n",
    "            # \"svc__degree\": [2, 3, 4, 5],\n",
    "            # \"svc__coef0\": [0.0, 0.5, 1.0],\n",
    "        }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # CV predictions from the selected (tuned) pipeline\n",
    "    y_pred_cv = cross_val_predict(best_model, X, y, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Classification Report (CV preds):\\n\", classification_report(y, y_pred_cv))\n",
    "    print(\"Confusion Matrix (CV preds):\\n\", confusion_matrix(y, y_pred_cv))\n",
    "    print(\"Time taken:\", pd.Timestamp.now() - start_time)\n",
    "\n",
    "    return best_model"
   ],
   "id": "6f5121321bced9f6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:39:36.982865Z",
     "start_time": "2026-02-15T22:39:33.413238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# randomize order in master_data_dropped and master_data_imputed\n",
    "master_data_dropped = master_data_dropped.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "master_data_imputed = master_data_imputed.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)"
   ],
   "id": "5d737be4d81a4e6e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T22:56:03.239252Z",
     "start_time": "2026-02-15T22:54:44.102161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run SVM with RBF kernel on 1% of master_data_dropped\n",
    "best_svm_rbf = svm_classifier_with_scaling(\n",
    "    df=master_data_dropped.sample(frac=0.01, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_dropped,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=2,\n",
    "    scoring=\"f1\",\n",
    "    kernel=\"rbf\",\n",
    ")"
   ],
   "id": "9513b9e782c160fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END ...........................................svc__C=1; total time=  14.2s\n",
      "[CV] END .........................................svc__C=0.1; total time=  14.5s\n",
      "[CV] END .........................................svc__C=0.1; total time=  14.6s\n",
      "[CV] END ...........................................svc__C=1; total time=  14.7s\n",
      "[CV] END ..........................................svc__C=10; total time=  17.6s\n",
      "[CV] END ..........................................svc__C=10; total time=  17.8s\n",
      "[CV] END .........................................svc__C=100; total time=  46.2s\n",
      "[CV] END .........................................svc__C=100; total time=  48.4s\n",
      "Best Hyperparameters: {'svc__C': 0.1}\n",
      "Classification Report (CV preds):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.69      0.65     13976\n",
      "        True       0.57      0.48      0.52     11970\n",
      "\n",
      "    accuracy                           0.60     25946\n",
      "   macro avg       0.59      0.59      0.59     25946\n",
      "weighted avg       0.59      0.60      0.59     25946\n",
      "\n",
      "Confusion Matrix (CV preds):\n",
      " [[9662 4314]\n",
      " [6184 5786]]\n",
      "Time taken: 0 days 00:01:18.787639\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T23:08:54.978627Z",
     "start_time": "2026-02-15T22:58:01.027826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run SVM with polynomial kernel on 1% of master_data_dropped\n",
    "best_svm_poly = svm_classifier_with_scaling(\n",
    "    df=master_data_dropped.sample(frac=0.01, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_dropped,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=2,\n",
    "    scoring=\"f1\",\n",
    "    kernel=\"poly\",\n",
    ")"
   ],
   "id": "d17d367a57ef691c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END .........................................svc__C=0.1; total time=   9.1s\n",
      "[CV] END .........................................svc__C=0.1; total time=   9.3s\n",
      "[CV] END ...........................................svc__C=1; total time=   9.7s\n",
      "[CV] END ...........................................svc__C=1; total time=   9.8s\n",
      "[CV] END ..........................................svc__C=10; total time=  15.0s\n",
      "[CV] END ..........................................svc__C=10; total time=  15.3s\n",
      "[CV] END .........................................svc__C=100; total time= 1.3min\n",
      "[CV] END .........................................svc__C=100; total time= 1.7min\n",
      "Best Hyperparameters: {'svc__C': 100}\n",
      "Classification Report (CV preds):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.62      0.60     13976\n",
      "        True       0.53      0.50      0.51     11970\n",
      "\n",
      "    accuracy                           0.56     25946\n",
      "   macro avg       0.56      0.56      0.56     25946\n",
      "weighted avg       0.56      0.56      0.56     25946\n",
      "\n",
      "Confusion Matrix (CV preds):\n",
      " [[8602 5374]\n",
      " [6023 5947]]\n",
      "Time taken: 0 days 00:10:53.534133\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run SVM with RBF kernel on 25% of master_data_imputed\n",
    "best_svm_rbf_imputed = svm_classifier_with_scaling(\n",
    "    df=master_data_imputed.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_imputed,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    scoring=\"f1\",\n",
    "    kernel=\"rbf\",\n",
    ")"
   ],
   "id": "15ed44d2a283cfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run SVM with polynomial kernel on 25% of master_data_imputed\n",
    "best_svm_poly_imputed = svm_classifier_with_scaling(\n",
    "    df=master_data_imputed.sample(frac=0.25, random_state=RANDOM_STATE),\n",
    "    target=target_variable,\n",
    "    features_list=features_list_imputed,\n",
    "    continuous_features=continuous_features,\n",
    "    cv_folds=5,\n",
    "    scoring=\"f1\",\n",
    "    kernel=\"poly\",\n",
    ")"
   ],
   "id": "28d11dd4cb1c15bc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
